{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from dputils import load_data, calc_mrr, evaluate\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7400cc4",
   "metadata": {},
   "source": [
    "#### Load WN18 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d731549",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2id, relation2id, train_triplets, valid_triplets, test_triplets = load_data('./data/wn18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d00767",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entity = len(entity2id)\n",
    "num_relation = len(relation2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0a440",
   "metadata": {},
   "source": [
    "#### Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(pos_samples, num_entity, negative_rate):\n",
    "    \n",
    "    size_of_batch = len(pos_samples)\n",
    "    num_to_generate = size_of_batch * negative_rate\n",
    "    neg_samples = np.tile(pos_samples, (negative_rate, 1))\n",
    "    labels = np.zeros(size_of_batch * (negative_rate + 1), dtype=np.float32)\n",
    "    labels[: size_of_batch] = 1\n",
    "    values = np.random.choice(num_entity, size=num_to_generate)\n",
    "    choices = np.random.uniform(size=num_to_generate)\n",
    "    subj = choices > 0.5\n",
    "    obj = choices <= 0.5\n",
    "    neg_samples[subj, 0] = values[subj]\n",
    "    neg_samples[obj, 2] = values[obj]\n",
    "\n",
    "    return np.concatenate((pos_samples, neg_samples)), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "def edge_normalization(edge_type, edge_index, num_entity, num_relation):\n",
    "    '''\n",
    "        Edge normalization trick\n",
    "        - one_hot: (num_edge, num_relation)\n",
    "        - deg: (num_node, num_relation)\n",
    "        - index: (num_edge)\n",
    "        - deg[edge_index[0]]: (num_edge, num_relation)\n",
    "        - edge_norm: (num_edge)\n",
    "    '''\n",
    "    one_hot = F.one_hot(edge_type.long(), num_classes = 2 * num_relation).to(torch.float)\n",
    "    deg = scatter_add(one_hot, edge_index[0], dim = 0, dim_size = num_entity)\n",
    "    index = edge_type + torch.arange(len(edge_index[0])) * (2 * num_relation)\n",
    "    edge_norm = 1 / deg[edge_index[0]].view(-1)[index]\n",
    "\n",
    "    return edge_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceafc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sampled_graph_and_labels(triplets, sample_size, split_size, num_entity, num_relation, negative_rate):\n",
    "    \"\"\"\n",
    "        Get training graph and signals\n",
    "        First perform edge neighborhood sampling on graph, then perform negative\n",
    "        sampling to generate negative samples\n",
    "    \"\"\"\n",
    "    def sample_edge_uniform(n_triples, sample_size):\n",
    "        \"\"\"Sample edges uniformly from all the edges.\"\"\"\n",
    "        all_edges = np.arange(n_triples)\n",
    "        return np.random.choice(all_edges, sample_size, replace=False)\n",
    "\n",
    "    edges = sample_edge_uniform(len(triplets), sample_size)\n",
    "\n",
    "    # Select sampled edges\n",
    "    edges = triplets[edges]\n",
    "    src, rel, dst = edges.transpose()\n",
    "    uniq_entity, edges = np.unique((src, dst), return_inverse=True)\n",
    "    src, dst = np.reshape(edges, (2, -1))\n",
    "    relabeled_edges = np.stack((src, rel, dst)).transpose()\n",
    "\n",
    "    # Negative sampling\n",
    "    samples, labels = negative_sampling(relabeled_edges, len(uniq_entity), negative_rate)\n",
    "\n",
    "    # further split graph, only half of the edges will be used as graph in message passing\n",
    "    # structure, while the rest half is used as unseen positive samples\n",
    "    split_size = int(sample_size * split_size)\n",
    "    graph_split_ids = np.random.choice(np.arange(sample_size),\n",
    "                                       size=split_size, replace=False)\n",
    "\n",
    "    src = torch.tensor(src[graph_split_ids], dtype = torch.long).contiguous()\n",
    "    dst = torch.tensor(dst[graph_split_ids], dtype = torch.long).contiguous()\n",
    "    rel = torch.tensor(rel[graph_split_ids], dtype = torch.long).contiguous()\n",
    "\n",
    "    # Create bi-directional graph\n",
    "    src, dst = torch.cat((src, dst)), torch.cat((dst, src))\n",
    "    rel = torch.cat((rel, rel + num_relation))\n",
    "\n",
    "    edge_index = torch.stack((src, dst))\n",
    "    edge_type = rel\n",
    "\n",
    "\n",
    "    entity = torch.from_numpy(uniq_entity)\n",
    "    edge_norm = edge_normalization(edge_type, edge_index, len(uniq_entity), num_relation)\n",
    "    samples = torch.from_numpy(samples)\n",
    "    labels = torch.from_numpy(labels)\n",
    "    \n",
    "    '''\n",
    "    # use in message propogation\n",
    "    entity : sampled unique entity ids, [0 < x < 2N]\n",
    "    edge_index: [2, N], pairs of (src, dst) node ids, positive only, bi-directional\n",
    "    edge_type: [N], bi-directional 0<x<36\n",
    "    edge_norm: [N], normalizating factor\n",
    "    \n",
    "    # use in loss calculation (single_direction)\n",
    "    samples: [3, 2N] : first half pos, sec half neg\n",
    "    labels: [2N]: [1,1,1,...0,0,0 ]\n",
    "    '''\n",
    "    \n",
    "    return entity, edge_index, edge_type, edge_norm, samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8123767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_graph(num_entity, num_relation, triplets):\n",
    "    src, rel, dst = triplets.transpose()\n",
    "\n",
    "    src = torch.from_numpy(src)\n",
    "    rel = torch.from_numpy(rel)\n",
    "    dst = torch.from_numpy(dst)\n",
    "\n",
    "    src, dst = torch.cat((src, dst)), torch.cat((dst, src))\n",
    "    rel = torch.cat((rel, rel + num_relation))\n",
    "\n",
    "    edge_index = torch.stack((src, dst)).long()\n",
    "    edge_type = rel\n",
    "\n",
    "    entity = torch.from_numpy(np.arange(num_entity))\n",
    "    edge_norm = edge_normalization(edge_type, edge_index, num_entity, num_relation)\n",
    "\n",
    "    return entity, edge_index, edge_type, edge_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005939ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full graph without sampling/neg sampling and spliting\n",
    "eval_graph = build_eval_graph(num_entity, num_relation, train_triplets) \n",
    "\n",
    "all_triplets = torch.LongTensor(np.concatenate((train_triplets, valid_triplets, test_triplets)))\n",
    "valid_triplets = torch.LongTensor(valid_triplets)\n",
    "test_triplets = torch.LongTensor(test_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee42d1",
   "metadata": {},
   "source": [
    "#### RGCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a130b97",
   "metadata": {},
   "source": [
    "##### MESSAGE PASSING NETWORKS\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\square$ denotes a differentiable, permutation invariant function, e.g., sum, mean or max, and $\\gamma$ and $\\phi$ denote differentiable functions such as MLPs (Multi Layer Perceptrons). The user only has to define these functions.\n",
    " \n",
    "\n",
    "##### RGCN\n",
    "\n",
    "The relational graph convolutional operator from the \"ModelingRelational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "\n",
    "\\begin{equation}\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where: $\\mathcal{R}$ denotes the set of relations, *i.e.* edge types. Edge type needs to be a one-dimensional :obj:`torch.long` tensor which stores a relation identifier\n",
    "    $\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}$ for each edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int): Number of bases used for basis-decomposition.\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_bases,\n",
    "                 root_weight=True, bias=True, **kwargs):\n",
    "        super(RGCNConv, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        self.basis = nn.Parameter(torch.Tensor(num_bases, in_channels, out_channels))\n",
    "        self.att = nn.Parameter(torch.Tensor(num_relations, num_bases))\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.num_bases * self.in_channels\n",
    "        uniform(size, self.basis)\n",
    "        uniform(size, self.att)\n",
    "        uniform(size, self.root)\n",
    "        uniform(size, self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type, edge_norm=None, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        return self.propagate(edge_index, size=size, x=x, edge_type=edge_type,\n",
    "                              edge_norm=edge_norm)\n",
    "\n",
    "\n",
    "    def message(self, x_j, edge_index_j, edge_type, edge_norm):\n",
    "        w = torch.matmul(self.att, self.basis.view(self.num_bases, -1))\n",
    "\n",
    "        # If no node features are given, we implement a simple embedding\n",
    "        # loopkup based on the target node index and its edge type.\n",
    "        if x_j is None:\n",
    "            w = w.view(-1, self.out_channels)\n",
    "            index = edge_type * self.in_channels + edge_index_j\n",
    "            out = torch.index_select(w, 0, index)\n",
    "        else:\n",
    "            w = w.view(self.num_relations, self.in_channels, self.out_channels)\n",
    "            w = torch.index_select(w, 0, edge_type)\n",
    "            out = torch.bmm(x_j.unsqueeze(1), w).squeeze(-2)\n",
    "\n",
    "        return out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        if self.root is not None:\n",
    "            if x is None:\n",
    "                out = aggr_out + self.root\n",
    "            else:\n",
    "                out = aggr_out + torch.matmul(x, self.root)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, num_relations={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels,\n",
    "            self.num_relations)\n",
    "\n",
    "def uniform(size, tensor):\n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, num_bases, dropout):\n",
    "        super(RGCN, self).__init__()\n",
    "\n",
    "        self.entity_embedding = nn.Embedding(num_entities, 100)\n",
    "        self.relation_embedding = nn.Parameter(torch.Tensor(num_relations, 100))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.relation_embedding, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        self.conv1 = RGCNConv(\n",
    "            100, 100, num_relations * 2, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(\n",
    "            100, 100, num_relations * 2, num_bases=num_bases)\n",
    "\n",
    "        self.dropout_ratio = dropout\n",
    "\n",
    "    def forward(self, entity, edge_index, edge_type, edge_norm):\n",
    "        x = self.entity_embedding(entity)\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_type, edge_norm))\n",
    "        x = F.dropout(x, p = self.dropout_ratio, training = self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type, edge_norm)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def distmult(self, embedding, triplets):\n",
    "        s = embedding[triplets[:,0]]\n",
    "        r = self.relation_embedding[triplets[:,1]]\n",
    "        o = embedding[triplets[:,2]]\n",
    "        score = torch.sum(s * r * o, dim=1)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def score_loss(self, embedding, triplets, target):\n",
    "        score = self.distmult(embedding, triplets)\n",
    "\n",
    "        return F.binary_cross_entropy_with_logits(score, target)\n",
    "\n",
    "    def reg_loss(self, embedding):\n",
    "        return torch.mean(embedding.pow(2)) + torch.mean(self.relation_embedding.pow(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe5270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3000\n",
    "split_size = 0.5\n",
    "negative_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b28c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "batch_size = 2000\n",
    "evaluate_interval = 500\n",
    "num_bases = 4\n",
    "dropout = 0.2\n",
    "lr = 0.01 \n",
    "grad_norm = 1.0\n",
    "regularization = 1e-2\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(num_entity, num_relation, num_bases=num_bases, dropout=dropout)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr )\n",
    "print(model)\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entity, edge_index, edge_type, edge_norm, samples, labels = generate_sampled_graph_and_labels(train_triplets,\n",
    "                                                                                  sample_size = batch_size,\n",
    "                                                                                  split_size = 0.5,\n",
    "                                                                                  num_entity = num_entity,\n",
    "                                                                                  num_relation = num_relation,\n",
    "                                                                                  negative_rate = negative_rate)\n",
    "\n",
    "if cuda:\n",
    "    entity = entity.cuda()\n",
    "    edge_index = edge_index.cuda()\n",
    "    edge_type = edge_type.cuda()\n",
    "    edge_norm = edge_norm.cuda()\n",
    "    samples = samples.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "entity_embedding = model(entity, edge_index, edge_type, edge_norm)\n",
    "loss = model.score_loss(entity_embedding, samples, labels) + regularization * model.reg_loss(entity_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d9667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_mrr  = 0.\n",
    "for epoch in trange(1, (num_epochs + 1), desc='Epochs', position=0):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # sample training data\n",
    "    entity, edge_index, edge_type, edge_norm, samples, labels = generate_sampled_graph_and_labels(train_triplets,\n",
    "                                                                                      sample_size = batch_size,\n",
    "                                                                                      split_size = 0.5,\n",
    "                                                                                      num_entity = num_entity,\n",
    "                                                                                      num_relation = num_relation,\n",
    "                                                                                      negative_rate = negative_rate)\n",
    "\n",
    "    if cuda:\n",
    "        entity = entity.cuda()\n",
    "        edge_index = edge_index.cuda()\n",
    "        edge_type = edge_type.cuda()\n",
    "        edge_norm = edge_norm.cuda()\n",
    "        samples = samples.cuda()\n",
    "        labels = labels.cuda()\n",
    "    \n",
    "    # traning and back prop\n",
    "    entity_embedding = model(entity, edge_index, edge_type, edge_norm)\n",
    "    loss = model.score_loss(entity_embedding, samples, labels) + regularization * model.reg_loss(entity_embedding)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % evaluate_interval == 0:\n",
    "\n",
    "        tqdm.write(\"Train Loss {} at epoch {}\".format(loss, epoch))\n",
    "\n",
    "        if cuda:\n",
    "            model.cpu()\n",
    "\n",
    "        model.eval()\n",
    "        valid_mrr = evaluate(valid_triplets, model, eval_graph, all_triplets)\n",
    "\n",
    "        if valid_mrr > best_mrr:\n",
    "            best_mrr = valid_mrr\n",
    "            torch.save({'state_dict': model.state_dict(), 'epoch': epoch},\n",
    "                        'best_mrr_model.pth')\n",
    "\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "\n",
    "if cuda:\n",
    "    model.cpu()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "checkpoint = torch.load('best_mrr_model.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "test_mrr = evaluate(test_triplets, model, eval_graph, all_triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa6ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cffa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-gpu] *",
   "language": "python",
   "name": "conda-env-pytorch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
